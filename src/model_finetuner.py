import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import logging
import yaml
import os
import json
import copy
from typing import Dict, List, Tuple, Any, Optional, Union
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from .model_trainer import DVMHEfficiencyMLP, DVMHAttentionModel, DVMHModelTrainer
from .feature_preprocessor import DVMHFeaturePreprocessor

logger = logging.getLogger(__name__)


class DVMHModelFineTuner:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è (fine-tuning) –º–æ–¥–µ–ª–µ–π DVMH
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
    """
    
    def __init__(self, config_path: str = "config/data_config.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è
        
        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.logger = logging.getLogger(f"dvmh_predictor.{__name__}")
        self.config = self._load_config(config_path)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        model_config = self.config.get('model_training', {})
        self.models_dir = model_config.get('models_directory', './models')
        self.finetune_dir = os.path.join(self.models_dir, 'finetuned')
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        os.makedirs(self.finetune_dir, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.base_model = None
        self.base_preprocessor = None
        self.base_metadata = None
        self.model_type = None
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –±–∞–∑–æ–≤–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
        self.base_trainer = DVMHModelTrainer(config_path)
        
        self.logger.info(f"DVMHModelFineTuner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
    
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            self.logger.warning(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
            return {}
    
    def load_base_model(self, model_name: str, model_type: str = 'mlp') -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        
        Args:
            model_name: –ò–º—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ ('mlp' –∏–ª–∏ 'attention')
            
        Returns:
            bool: True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è: {model_name}")
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        model_path = os.path.join(self.models_dir, f"{model_name}.pt")
        metadata_path = os.path.join(self.models_dir, f"{model_name}_metadata.json")
        
        if not os.path.exists(model_path) or not os.path.exists(metadata_path):
            self.logger.error(f"–§–∞–π–ª—ã –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {model_path}, {metadata_path}")
            return False
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            with open(metadata_path, 'r', encoding='utf-8') as f:
                self.base_metadata = json.load(f)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            self.base_preprocessor = checkpoint['preprocessor']
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            input_dim = self.base_metadata['input_dim']
            hidden_dims = self.base_metadata['hidden_dims']
            self.model_type = model_type.lower()
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            if self.model_type == 'attention':
                attention_dim = self.base_metadata.get('attention_dim', 64)
                self.base_model = DVMHAttentionModel(input_dim, hidden_dims, attention_dim)
            else:
                self.base_model = DVMHEfficiencyMLP(input_dim, hidden_dims)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            self.base_model.load_state_dict(checkpoint['model_state_dict'])
            self.base_model.to(self.device)
            
            self.logger.info(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            self.logger.info(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {hidden_dims}, —Ç–∏–ø: {self.model_type}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")
            return False
    
    def prepare_finetuning_data(self, new_df: pd.DataFrame, target_column: str = 'target_speedup',
                               validation_split: float = 0.2, 
                               adaptation_strategy: str = 'extend_preprocessor') -> Dict:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        
        Args:
            new_df: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
            target_column: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            validation_split: –î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
            adaptation_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ ('extend_preprocessor', 'refit_preprocessor', 'use_existing')
            
        Returns:
            Dict: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        self.logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {adaptation_strategy}")
        
        if self.base_preprocessor is None:
            raise ValueError("–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        new_df_copy = new_df.copy()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        y_new = new_df_copy[target_column].copy()
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        if y_new.isna().any():
            target_median = y_new.median()
            y_new = y_new.fillna(target_median)
            self.logger.info(f"–ó–∞–ø–æ–ª–Ω–µ–Ω—ã NaN –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ–¥–∏–∞–Ω–æ–π: {target_median}")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        if adaptation_strategy == 'extend_preprocessor':
            # –†–∞—Å—à–∏—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–æ–≤—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            X_new_processed = self._extend_preprocessor(new_df_copy, target_column)
            
        elif adaptation_strategy == 'refit_preprocessor':
            # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            self.logger.warning("–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é")
            new_preprocessor = DVMHFeaturePreprocessor()
            X_new_processed = new_preprocessor.fit_transform(new_df_copy, target_column)
            self.base_preprocessor = new_preprocessor
            
        elif adaptation_strategy == 'use_existing':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∫–∞–∫ –µ—Å—Ç—å
            X_new_processed = self.base_preprocessor.transform(new_df_copy)
            
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏: {adaptation_strategy}")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
        if validation_split > 0:
            X_train, X_val, y_train, y_val = train_test_split(
                X_new_processed, y_new, test_size=validation_split, random_state=42
            )
        else:
            X_train, X_val = X_new_processed, None
            y_train, y_val = y_new.values, None
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        X_train = X_train.astype(np.float32)
        y_train = y_train.astype(np.float32) if isinstance(y_train, np.ndarray) else y_train.values.astype(np.float32)
        
        if X_val is not None:
            X_val = X_val.astype(np.float32)
            y_val = y_val.astype(np.float32) if isinstance(y_val, np.ndarray) else y_val.values.astype(np.float32)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        for name, data in [('X_train', X_train), ('y_train', y_train)]:
            if data is not None:
                nan_count = np.isnan(data).sum()
                if nan_count > 0:
                    self.logger.warning(f"NaN –≤ {name}: {nan_count}. –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ 0.")
                    data = np.nan_to_num(data, nan=0.0 if 'X_' in name else 1.0)
        
        if X_val is not None and y_val is not None:
            for name, data in [('X_val', X_val), ('y_val', y_val)]:
                nan_count = np.isnan(data).sum()
                if nan_count > 0:
                    self.logger.warning(f"NaN –≤ {name}: {nan_count}. –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ 0.")
                    data = np.nan_to_num(data, nan=0.0 if 'X_' in name else 1.0)
        
        self.logger.info(f"–î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: train={X_train.shape}, val={X_val.shape if X_val is not None else None}")
        
        return {
            'X_train': X_train,
            'X_val': X_val,
            'y_train': y_train,
            'y_val': y_val,
            'feature_names': self.base_preprocessor.get_feature_names(),
            'preprocessor': self.base_preprocessor,
            'adaptation_strategy': adaptation_strategy
        }
    
    def _extend_preprocessor(self, df: pd.DataFrame, target_column: str) -> np.ndarray:
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –Ω–æ–≤—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        
        Args:
            df: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            target_column: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            
        Returns:
            np.ndarray: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        """
        self.logger.info("–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –Ω–æ–≤—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏...")
        
        df_work = df.copy()
        
        # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        columns_to_drop = [col for col in self.base_preprocessor.exclude_columns + [target_column] 
                          if col in df_work.columns]
        if columns_to_drop:
            df_work = df_work.drop(columns=columns_to_drop)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        new_categories_found = False
        
        for col in self.base_preprocessor.categorical_columns:
            if col in df_work.columns:
                df_work[col] = df_work[col].fillna("unknown")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                existing_categories = set(self.base_preprocessor.categorical_mappings[col].keys())
                new_values = set(df_work[col].unique()) - existing_categories
                
                if new_values:
                    new_categories_found = True
                    self.logger.info(f"–ù–∞–π–¥–µ–Ω—ã –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ '{col}': {new_values}")
                    
                    # –†–∞—Å—à–∏—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥
                    max_existing_idx = max(self.base_preprocessor.categorical_mappings[col].values())
                    for i, new_value in enumerate(sorted(new_values)):
                        new_idx = max_existing_idx + i + 1
                        self.base_preprocessor.categorical_mappings[col][new_value] = new_idx
                        self.logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{new_value}' -> {new_idx}")
        
        if new_categories_found:
            self.logger.info("–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ä–∞—Å—à–∏—Ä–µ–Ω –Ω–æ–≤—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        return self.base_preprocessor.transform(df)
    
    def fine_tune_model(self, data: Dict, 
                   fine_tune_strategy: str = 'full_model',
                   learning_rate: float = 0.0001,
                   epochs: int = 50,
                   batch_size: int = 64,
                   patience: int = 10,
                   freeze_layers: Optional[List[str]] = None,
                   weight_decay: float = 0.01) -> Tuple[nn.Module, Dict]:
      """
      –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
      
      Args:
          data: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
          fine_tune_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–æ–±—É—á–µ–Ω–∏—è ('full_model', 'last_layers', 'adapter', 'gradual_unfreezing')
          learning_rate: –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ –º–µ–Ω—å—à–µ —á–µ–º –ø—Ä–∏ –ø–æ–ª–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏)
          epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
          batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
          patience: –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
          freeze_layers: –°–ø–∏—Å–æ–∫ —Å–ª–æ–µ–≤ –¥–ª—è –∑–∞–º–æ—Ä–æ–∑–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
          weight_decay: –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
          
      Returns:
          Tuple: –î–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∏ –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
      """
      self.logger.info(f"–ù–∞—á–∞–ª–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {fine_tune_strategy}")
      
      if self.base_model is None:
          raise ValueError("–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
      
      # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
      finetuned_model = copy.deepcopy(self.base_model)
      finetuned_model.train()
      
      # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–æ–æ–±—É—á–µ–Ω–∏—è
      self._apply_fine_tune_strategy(finetuned_model, fine_tune_strategy, freeze_layers)
      
      # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
      trainable_params = list(filter(lambda p: p.requires_grad, finetuned_model.parameters()))
      if not trainable_params:
          if fine_tune_strategy == 'gradual_unfreezing':
              # –î–ª—è gradual_unfreezing —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –¥–ª—è –Ω–∞—á–∞–ª–∞
              self.logger.warning("–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã, —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π")
              if hasattr(finetuned_model, 'model') and hasattr(finetuned_model.model, '__getitem__'):
                  # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
                  for param in finetuned_model.model[-1].parameters():
                      param.requires_grad = True
                  trainable_params = list(filter(lambda p: p.requires_grad, finetuned_model.parameters()))
          
          if not trainable_params:
              raise ValueError(f"–ù–µ—Ç –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {fine_tune_strategy}")
      
      self.logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(trainable_params)}")
      
      # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
      X_train = data['X_train']
      y_train = data['y_train']
      X_val = data['X_val']
      y_val = data['y_val']
      
      # –°–æ–∑–¥–∞–µ–º DataLoader'—ã
      train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))
      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
      
      val_loader = None
      if X_val is not None and y_val is not None:
          val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))
          val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
      
      # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
      optimizer = optim.Adam(
          trainable_params,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
          lr=learning_rate,
          weight_decay=weight_decay
      )
      
      # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ scheduler –±–µ–∑ verbose –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
      try:
          # –ü—Ä–æ–±—É–µ–º —Å verbose (–Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ PyTorch)
          scheduler = optim.lr_scheduler.ReduceLROnPlateau(
              optimizer, mode='min', factor=0.5, patience=patience//2, verbose=True
          )
      except TypeError:
          # Fallback –±–µ–∑ verbose (—Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ PyTorch)
          self.logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è scheduler –±–µ–∑ verbose (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è PyTorch)")
          scheduler = optim.lr_scheduler.ReduceLROnPlateau(
              optimizer, mode='min', factor=0.5, patience=patience//2
          )
      
      criterion = nn.MSELoss()
      
      # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
      history = {
          'train_loss': [],
          'val_loss': [],
          'train_r2': [],
          'val_r2': [],
          'learning_rates': []
      }
      
      best_val_loss = float('inf')
      patience_counter = 0
      best_model_state = None
      
      self.logger.info(f"–ù–∞—á–∞–ª–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ {epochs} —ç–ø–æ—Ö...")
      
      for epoch in range(epochs):
          # –û–±—É—á–µ–Ω–∏–µ
          finetuned_model.train()
          train_losses = []
          train_predictions = []
          train_targets = []
          
          for batch_X, batch_y in train_loader:
              batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
              
              optimizer.zero_grad()
              
              if self.model_type == 'attention':
                  predictions, _ = finetuned_model(batch_X)
              else:
                  predictions = finetuned_model(batch_X)
              
              loss = criterion(predictions, batch_y)
              loss.backward()
              
              # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
              torch.nn.utils.clip_grad_norm_(finetuned_model.parameters(), max_norm=1.0)
              
              optimizer.step()
              
              train_losses.append(loss.item())
              train_predictions.extend(predictions.detach().cpu().numpy())
              train_targets.extend(batch_y.detach().cpu().numpy())
          
          # –í–∞–ª–∏–¥–∞—Ü–∏—è
          val_loss = 0.0
          val_predictions = []
          val_targets = []
          
          if val_loader is not None:
              finetuned_model.eval()
              with torch.no_grad():
                  for batch_X, batch_y in val_loader:
                      batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                      
                      if self.model_type == 'attention':
                          predictions, _ = finetuned_model(batch_X)
                      else:
                          predictions = finetuned_model(batch_X)
                      
                      loss = criterion(predictions, batch_y)
                      val_loss += loss.item()
                      
                      val_predictions.extend(predictions.cpu().numpy())
                      val_targets.extend(batch_y.cpu().numpy())
              
              val_loss /= len(val_loader)
          else:
              val_loss = np.mean(train_losses)
              val_predictions = train_predictions
              val_targets = train_targets
          
          # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
          train_loss = np.mean(train_losses)
          train_r2 = r2_score(train_targets, train_predictions)
          val_r2 = r2_score(val_targets, val_predictions)
          
          # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
          history['train_loss'].append(train_loss)
          history['val_loss'].append(val_loss)
          history['train_r2'].append(train_r2)
          history['val_r2'].append(val_r2)
          history['learning_rates'].append(optimizer.param_groups[0]['lr'])
          
          # –û–±–Ω–æ–≤–ª—è–µ–º learning rate
          scheduler.step(val_loss)
          
          # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
          if epoch % 10 == 0 or epoch < 10:
              self.logger.info(f"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, "
                            f"train_r2={train_r2:.4f}, val_r2={val_r2:.4f}, lr={optimizer.param_groups[0]['lr']:.6f}")
          
          # –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
          if val_loss < best_val_loss:
              best_val_loss = val_loss
              patience_counter = 0
              best_model_state = finetuned_model.state_dict().copy()
          else:
              patience_counter += 1
              if patience_counter >= patience:
                  self.logger.info(f"–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}")
                  break
          
          # –ì—Ä–∞–¥—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
          if fine_tune_strategy == 'gradual_unfreezing' and epoch > 0 and epoch % 10 == 0:
              self._gradual_unfreeze_fixed(finetuned_model, epoch, optimizer)
      
      # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–µ –≤–µ—Å–∞
      if best_model_state is not None:
          finetuned_model.load_state_dict(best_model_state)
      
      self.logger.info("–î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
      return finetuned_model, history
    
    def _apply_fine_tune_strategy(self, model: nn.Module, strategy: str, freeze_layers: Optional[List[str]] = None):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
        
        if strategy == 'full_model':
            # –î–æ–æ–±—É—á–∞–µ–º –≤—Å—é –º–æ–¥–µ–ª—å
            for param in model.parameters():
                param.requires_grad = True
            self.logger.info("–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –¥–æ–æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ–π –º–æ–¥–µ–ª–∏")
            
        elif strategy == 'last_layers':
            # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–∏, –¥–æ–æ–±—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ
            if hasattr(model, 'model') and hasattr(model.model, '__getitem__'):
                # –î–ª—è MLP –º–æ–¥–µ–ª–∏
                total_layers = len(model.model)
                freeze_until = max(1, total_layers - 4)  # –î–æ–æ–±—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–ª–æ—è
                
                for i, layer in enumerate(model.model):
                    if i < freeze_until:
                        for param in layer.parameters():
                            param.requires_grad = False
                    else:
                        for param in layer.parameters():
                            param.requires_grad = True
                            
                self.logger.info(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã –ø–µ—Ä–≤—ã–µ {freeze_until} —Å–ª–æ–µ–≤")
            else:
                # –î–ª—è Attention –º–æ–¥–µ–ª–∏
                for name, param in model.named_parameters():
                    if 'embedding' in name or 'query' in name or 'key' in name:
                        param.requires_grad = False
                    else:
                        param.requires_grad = True
                self.logger.info("–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã embedding –∏ attention —Å–ª–æ–∏")
                
        elif strategy == 'adapter':
            # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å, –¥–æ–±–∞–≤–ª—è–µ–º –∞–¥–∞–ø—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–∏
            for param in model.parameters():
                param.requires_grad = False
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ –æ–±—É—á–∞–µ–º—ã–µ —Å–ª–æ–∏ (–∞–¥–∞–ø—Ç–µ—Ä—ã)
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            self.logger.info("–°—Ç—Ä–∞—Ç–µ–≥–∏—è: adapter-based fine-tuning (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
            
        elif strategy == 'gradual_unfreezing':
            # –ù–∞—á–∏–Ω–∞–µ–º —Å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            for param in model.parameters():
                param.requires_grad = False
            self.logger.info("–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –≥—Ä–∞–¥—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ (–Ω–∞—á–∏–Ω–∞–µ–º —Å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)")
            
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–º–æ—Ä–æ–∑–∫–∏
        if freeze_layers:
            for name, param in model.named_parameters():
                if any(layer_name in name for layer_name in freeze_layers):
                    param.requires_grad = False
                    self.logger.debug(f"–ó–∞–º–æ—Ä–æ–∂–µ–Ω —Å–ª–æ–π: {name}")
    
    def _gradual_unfreeze(self, model: nn.Module, epoch: int):
        """–ì—Ä–∞–¥—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ —Å–ª–æ–µ–≤"""
        if hasattr(model, 'model') and hasattr(model.model, '__getitem__'):
            total_layers = len(model.model)
            unfreeze_layer = min(epoch // 10, total_layers - 1)
            
            if unfreeze_layer < total_layers:
                for param in model.model[unfreeze_layer].parameters():
                    param.requires_grad = True
                self.logger.info(f"–†–∞–∑–º–æ—Ä–æ–∂–µ–Ω —Å–ª–æ–π {unfreeze_layer}")
    
    def evaluate_finetuned_model(self, model: nn.Module, test_data: Dict) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        self.logger.info("–û—Ü–µ–Ω–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        
        if 'X_test' not in test_data or 'y_test' not in test_data:
            self.logger.warning("–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã")
            return {}
        
        model.eval()
        model = model.to(self.device)
        
        X_test = test_data['X_test']
        y_test = test_data['y_test']
        
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test).to(self.device)
            
            if self.model_type == 'attention':
                predictions, attention_weights = model(X_test_tensor)
                attention_weights = attention_weights.cpu().numpy()
            else:
                predictions = model(X_test_tensor)
                attention_weights = None
            
            predictions = predictions.cpu().numpy()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)
        r2 = r2_score(y_test, predictions)
        rmse = np.sqrt(mse)
        
        metrics = {
            'mse': mse,
            'mae': mae,
            'rmse': rmse,
            'r2': r2
        }
        
        self.logger.info("–ú–µ—Ç—Ä–∏–∫–∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:")
        for metric, value in metrics.items():
            self.logger.info(f"  {metric}: {value:.4f}")
        
        if self.model_type == 'attention':
            return metrics, attention_weights
        else:
            return metrics
    
    def compare_models(self, original_metrics: Dict, finetuned_metrics: Dict) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        comparison = {}
        
        for metric in original_metrics:
            if metric in finetuned_metrics:
                original_val = original_metrics[metric]
                finetuned_val = finetuned_metrics[metric]
                
                if metric in ['mse', 'mae', 'rmse']:
                    # –î–ª—è —ç—Ç–∏—Ö –º–µ—Ç—Ä–∏–∫ –º–µ–Ω—å—à–µ = –ª—É—á—à–µ
                    improvement = ((original_val - finetuned_val) / original_val) * 100
                else:  # r2
                    # –î–ª—è R¬≤ –±–æ–ª—å—à–µ = –ª—É—á—à–µ
                    improvement = ((finetuned_val - original_val) / original_val) * 100
                
                comparison[metric] = {
                    'original': original_val,
                    'finetuned': finetuned_val,
                    'improvement_percent': improvement
                }
        
        self.logger.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:")
        for metric, values in comparison.items():
            self.logger.info(f"  {metric}: {values['original']:.4f} -> {values['finetuned']:.4f} "
                           f"({values['improvement_percent']:+.2f}%)")
        
        return comparison
    
    def save_finetuned_model(self, model: nn.Module, base_model_name: str, 
                           suffix: str = None, metadata: Dict = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if suffix:
            finetuned_name = f"{base_model_name}_ft_{suffix}_{timestamp}"
        else:
            finetuned_name = f"{base_model_name}_finetuned_{timestamp}"
        
        # –ü—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        model_path = os.path.join(self.finetune_dir, f"{finetuned_name}.pt")
        metadata_path = os.path.join(self.finetune_dir, f"{finetuned_name}_metadata.json")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        torch.save({
            'model_state_dict': model.state_dict(),
            'preprocessor': self.base_preprocessor,
            'base_model_name': base_model_name,
            'fine_tune_timestamp': timestamp
        }, model_path, pickle_protocol=4)
        
        # –î–æ–ø–æ–ª–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if metadata is None:
            metadata = {}
        
        metadata.update({
            'base_model_name': base_model_name,
            'fine_tune_timestamp': timestamp,
            'model_type': self.base_metadata.get('model_type', 'Unknown'),
            'input_dim': self.base_metadata.get('input_dim', 0),
            'hidden_dims': self.base_metadata.get('hidden_dims', []),
            'feature_names': self.base_preprocessor.get_feature_names(),
            'is_finetuned': True
        })
        
        metadata.update(self.base_preprocessor.get_metadata())
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
    
    def plot_fine_tuning_results(self, history: Dict, comparison: Dict = None) -> plt.Figure:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
        
        if comparison:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        else:
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))
        
        # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
        ax1.plot(history['train_loss'], label='Train Loss', color='blue')
        ax1.plot(history['val_loss'], label='Validation Loss', color='red')
        ax1.set_title('Fine-tuning Loss Curves')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # –ì—Ä–∞—Ñ–∏–∫ R¬≤
        ax2.plot(history['train_r2'], label='Train R¬≤', color='green')
        ax2.plot(history['val_r2'], label='Validation R¬≤', color='orange')
        ax2.set_title('Fine-tuning R¬≤ Score')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('R¬≤ Score')
        ax2.legend()
        ax2.grid(True)
        
        # –ì—Ä–∞—Ñ–∏–∫ learning rate
        ax3.plot(history['learning_rates'], label='Learning Rate', color='purple')
        ax3.set_title('Learning Rate Schedule')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Learning Rate')
        ax3.set_yscale('log')
        ax3.legend()
        ax3.grid(True)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if comparison:
            metrics = list(comparison.keys())
            original_values = [comparison[m]['original'] for m in metrics]
            finetuned_values = [comparison[m]['finetuned'] for m in metrics]
            
            x = np.arange(len(metrics))
            width = 0.35
            
            ax4.bar(x - width/2, original_values, width, label='Original Model', alpha=0.8)
            ax4.bar(x + width/2, finetuned_values, width, label='Fine-tuned Model', alpha=0.8)
            
            ax4.set_title('Model Comparison')
            ax4.set_xlabel('Metrics')
            ax4.set_ylabel('Values')
            ax4.set_xticks(x)
            ax4.set_xticklabels(metrics)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã —É–ª—É—á—à–µ–Ω–∏—è
            for i, metric in enumerate(metrics):
                improvement = comparison[metric]['improvement_percent']
                ax4.text(i, max(original_values[i], finetuned_values[i]) * 1.05, 
                        f'{improvement:+.1f}%', ha='center', va='bottom')
        
        plt.tight_layout()
        return fig
    
    def run_comprehensive_fine_tuning(self, new_df: pd.DataFrame, base_model_name: str,
                                    model_type: str = 'mlp',
                                    target_column: str = 'target_speedup',
                                    test_df: pd.DataFrame = None,
                                    fine_tune_strategies: List[str] = None,
                                    validation_split: float = 0.2,
                                    adaptation_strategy: str = 'extend_preprocessor',
                                    learning_rate: float = 0.0001,
                                    epochs: int = 50,
                                    batch_size: int = 64,
                                    patience: int = 10) -> Dict:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        
        Args:
            new_df: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
            base_model_name: –ò–º—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏
            target_column: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            test_df: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            fine_tune_strategies: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            validation_split: –î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
            adaptation_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            learning_rate: –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            patience: –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        self.logger.info("=" * 80)
        self.logger.info("–ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –î–û–û–ë–£–ß–ï–ù–ò–Ø")
        self.logger.info("=" * 80)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        if not self.load_base_model(base_model_name, model_type):
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å {base_model_name}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è...")
        data = self.prepare_finetuning_data(
            new_df, target_column, validation_split, adaptation_strategy
        )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –µ—Å—Ç—å
        test_data = {}
        if test_df is not None:
            self.logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            y_test = test_df[target_column].copy()
            if y_test.isna().any():
                y_test = y_test.fillna(y_test.median())
            
            X_test = self.base_preprocessor.transform(test_df)
            test_data = {
                'X_test': X_test.astype(np.float32),
                'y_test': y_test.values.astype(np.float32)
            }
            self.logger.info(f"–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X_test.shape}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if fine_tune_strategies is None:
            fine_tune_strategies = ['full_model', 'last_layers', 'gradual_unfreezing']
        
        self.logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {fine_tune_strategies}")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        base_metrics = {}
        if test_data:
            self.logger.info("–û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
            if self.model_type == 'attention':
                base_metrics, _ = self.evaluate_finetuned_model(self.base_model, test_data)
            else:
                base_metrics = self.evaluate_finetuned_model(self.base_model, test_data)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        results = {
            'base_model_metrics': base_metrics,
            'strategies_results': {},
            'best_strategy': None,
            'best_metrics': None,
            'data_info': {
                'train_size': len(data['X_train']),
                'val_size': len(data['X_val']) if data['X_val'] is not None else 0,
                'test_size': len(test_data['X_test']) if test_data else 0,
                'adaptation_strategy': adaptation_strategy
            }
        }
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_dir = os.path.join(self.finetune_dir, 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        best_r2 = -float('inf')
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
        for strategy in fine_tune_strategies:
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ò: {strategy.upper()}")
            self.logger.info(f"{'='*60}")
            
            try:
                # –î–æ–æ–±—É—á–µ–Ω–∏–µ
                finetuned_model, history = self.fine_tune_model(
                    data=data,
                    fine_tune_strategy=strategy,
                    learning_rate=learning_rate,
                    epochs=epochs,
                    batch_size=batch_size,
                    patience=patience
                )
                
                # –û—Ü–µ–Ω–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                finetuned_metrics = {}
                comparison = {}
                
                if test_data:
                    if self.model_type == 'attention':
                        finetuned_metrics, _ = self.evaluate_finetuned_model(finetuned_model, test_data)
                    else:
                        finetuned_metrics = self.evaluate_finetuned_model(finetuned_model, test_data)
                    
                    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
                    comparison = self.compare_models(base_metrics, finetuned_metrics)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                model_name = self.save_finetuned_model(
                    finetuned_model, 
                    base_model_name, 
                    suffix=strategy,
                    metadata={
                        'fine_tune_strategy': strategy,
                        'learning_rate': learning_rate,
                        'epochs': epochs,
                        'batch_size': batch_size,
                        'metrics': finetuned_metrics,
                        'comparison': comparison
                    }
                )
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
                fig = self.plot_fine_tuning_results(history, comparison)
                fig.savefig(os.path.join(results_dir, f'{strategy}_results.png'), 
                           dpi=300, bbox_inches='tight')
                plt.close(fig)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                strategy_results = {
                    'model_name': model_name,
                    'history': history,
                    'metrics': finetuned_metrics,
                    'comparison': comparison,
                    'final_train_loss': history['train_loss'][-1],
                    'final_val_loss': history['val_loss'][-1],
                    'final_train_r2': history['train_r2'][-1],
                    'final_val_r2': history['val_r2'][-1]
                }
                
                results['strategies_results'][strategy] = strategy_results
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ R¬≤
                current_r2 = finetuned_metrics.get('r2', -float('inf'))
                if current_r2 > best_r2:
                    best_r2 = current_r2
                    results['best_strategy'] = strategy
                    results['best_metrics'] = finetuned_metrics
                
                self.logger.info(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy}: {str(e)}")
                results['strategies_results'][strategy] = {
                    'error': str(e),
                    'status': 'failed'
                }
        
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        self.logger.info("\n" + "="*80)
        self.logger.info("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –î–û–û–ë–£–ß–ï–ù–ò–Ø")
        self.logger.info("="*80)
        
        if results['best_strategy']:
            self.logger.info(f"üèÜ –õ—É—á—à–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {results['best_strategy']}")
            self.logger.info(f"üéØ –õ—É—á—à–∏–π R¬≤: {results['best_metrics']['r2']:.4f}")
            
            if base_metrics:
                base_r2 = base_metrics.get('r2', 0)
                improvement = ((results['best_metrics']['r2'] - base_r2) / base_r2) * 100
                self.logger.info(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ R¬≤: {improvement:+.2f}%")
        
        self.logger.info("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:")
        for strategy, strategy_results in results['strategies_results'].items():
            if 'error' not in strategy_results:
                final_r2 = strategy_results['final_val_r2']
                self.logger.info(f"  {strategy}: R¬≤ = {final_r2:.4f}")
            else:
                self.logger.info(f"  {strategy}: –û–®–ò–ë–ö–ê - {strategy_results['error']}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞
        report_path = os.path.join(results_dir, f'fine_tuning_report_{base_model_name}.json')
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON (—É–±–∏—Ä–∞–µ–º numpy arrays)
        json_results = copy.deepcopy(results)
        for strategy in json_results['strategies_results']:
            if 'history' in json_results['strategies_results'][strategy]:
                del json_results['strategies_results'][strategy]['history']
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_dir}")
        self.logger.info("üéâ –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        return results
    
    def list_finetuned_models(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if not os.path.exists(self.finetune_dir):
            return []
        
        models = []
        for file in os.listdir(self.finetune_dir):
            if file.endswith('.pt'):
                model_name = file[:-3]
                metadata_path = os.path.join(self.finetune_dir, f"{model_name}_metadata.json")
                
                if os.path.exists(metadata_path):
                    try:
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        models.append({
                            'name': model_name,
                            'base_model': metadata.get('base_model_name', 'Unknown'),
                            'timestamp': metadata.get('fine_tune_timestamp', 'Unknown'),
                            'strategy': metadata.get('fine_tune_strategy', 'Unknown'),
                            'r2_score': metadata.get('metrics', {}).get('r2', 'Unknown'),
                            'path': os.path.join(self.finetune_dir, file)
                        })
                    except:
                        continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
        models.sort(key=lambda x: x['timestamp'], reverse=True)
        return models
    
    def _gradual_unfreeze_fixed(self, model: nn.Module, epoch: int, optimizer: optim.Optimizer):
      """–ì—Ä–∞–¥—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ —Å–ª–æ–µ–≤ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
      if hasattr(model, 'model') and hasattr(model.model, '__getitem__'):
          total_layers = len(model.model)
          layers_to_unfreeze = min((epoch // 10) + 1, total_layers)  # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –±–æ–ª—å—à–µ —Å–ª–æ–µ–≤ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ
          
          # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Å–ª–æ–∏ —Å –∫–æ–Ω—Ü–∞
          for i in range(max(0, total_layers - layers_to_unfreeze), total_layers):
              layer_unfrozen = False
              for param in model.model[i].parameters():
                  if not param.requires_grad:
                      param.requires_grad = True
                      layer_unfrozen = True
              
              if layer_unfrozen:
                  self.logger.info(f"–†–∞–∑–º–æ—Ä–æ–∂–µ–Ω —Å–ª–æ–π {i}")
          
          # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
          trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))
          if trainable_params:
              # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
              optimizer.param_groups[0]['params'] = trainable_params
              self.logger.debug(f"–û–±–Ω–æ–≤–ª–µ–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {len(trainable_params)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")